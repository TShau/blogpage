The origin of Deep Learning comes from the inspiration of hierarchical architectures of neural network systems by stacking several layers of learning blocks for feature learning.
Multiple levels of learning blocks enable different representations and abstractions of the previous level as input.
Training those layers makes it possible to make sense of raw data and create a good representation of it.

The below figure exemplifies different levels of feature representation with images.
The input for the first layer is the raw pixel data from the image.
After further abstraction to higher levels, whole objects can be recognized from the raw pixel input.
Being able to understand abstract features enables better learning of specific tasks.
What makes Deep Learning so promising is the efficient computing of those features compared to laborious hand-crafted methods for feature extraction.
Most Deep Learning architectures involve artificial neural network models, like deep belief net-works, deep Boltzmann machines, or convolutional neural networks (CNN).

![image-center]({{ site.url }}{{ site.baseurl }}/assets/pics/Deeplearning-representation.png){: .align-center}

For a better understanding, the following sections introduce Deep Learning, starting with basic machine learning models like neural networks to deep structured CNN.
In the process, the mathematical background, architecture, and diverse techniques of machine learning shall be explained.
